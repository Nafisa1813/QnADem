{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6d79d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "body {\n",
       "  background: linear-gradient(to right, #20B2AA, #87CEFA);\n",
       "}\n",
       "\n",
       ".lbl_bg {\n",
       "  background-color: #8A8A8A;\n",
       "  color: white;\n",
       "  border-radius: 10px;\n",
       "  padding: 20px;\n",
       "  box-shadow: 4px 4px 4px #708090;\n",
       "}\n",
       "\n",
       ".box_style {\n",
       "  width: 50%;\n",
       "  border: 4px solid #FF00FF;\n",
       "  height: auto;\n",
       "  background: linear-gradient(to right, #90EE90, #32CD32);\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 4px 4px 4px #708090;\n",
       "  padding: 20px;\n",
       "}\n",
       "\n",
       ".box_style1 {\n",
       "  width: 90%;\n",
       "  \n",
       "  font-size: 50px;\n",
       "  background: linear-gradient(to right, #000000, #000000);\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 4px 4px 4px #708090;\n",
       "  border: 5px solid #708090;\n",
       "  color: #FFFFFF;\n",
       "  margin: auto;                             \n",
       "  padding: 10px;\n",
       "  border-radius: 10px;\n",
       "  cursor: pointer;\n",
       "  text-align: center;\n",
       "  display: flex;\n",
       "  align-items: center;\n",
       "}\n",
       ".box_style3 {\n",
       "  width: 90%;\n",
       "  \n",
       "  font-size: 50px;\n",
       "  background: linear-gradient(to right, #000000, #000000);\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 4px 4px 4px #708090;\n",
       "  border: 5px solid #708090;\n",
       "  color: #FFFFFF;\n",
       "  margin: auto;                             \n",
       "  padding: 10px;\n",
       "  border-radius: 10px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".radio_style1 {\n",
       "  width: 50%;\n",
       "  border: 4px solid #FF00FF;\n",
       "  height: auto;\n",
       "  background: linear-gradient(to right, #7FFFD4, #00FFFF);\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 4px 4px 4px #708090;\n",
       "  padding: 20px;\n",
       "}\n",
       "\n",
       ".box_style2 {\n",
       "  width: 90%;\n",
       "  border: 2px solid #708090;\n",
       "  height: auto;\n",
       "  background: linear-gradient(to right, #8A8A8A, #8A8A8A);\n",
       "  border-radius: 10px;\n",
       "  box-shadow: 4px 4px 4px #708090;\n",
       "  padding: 20px;\n",
       "  color: ##9F9FFF\n",
       "            \n",
       "}\n",
       "\n",
       ".top_spacing {\n",
       "  margin-top: 30px;\n",
       "}\n",
       "\n",
       ".left_spacing {\n",
       "  margin-left: 0px;\n",
       "}\n",
       "\n",
       ".left_spacing_2 {\n",
       "  margin-left: 300px;\n",
       "}\n",
       "\n",
       ".button_style {\n",
       "  border: 5px solid #708090;\n",
       "  background: linear-gradient(to right, #171717, #171717);\n",
       "  color: #1E90FF;\n",
       "  height: auto;                             \n",
       "  padding: 10px;\n",
       "  border-radius: 10px;\n",
       "  font-size: 15px;\n",
       "  box-shadow: 4px 4px 4px #708090;\n",
       "  cursor: pointer;\n",
       "  margin: auto\n",
       "}\n",
       "\n",
       ".top_spacing_2 {\n",
       "  margin-top: -30px;\n",
       "}\n",
       ".white_label { color:white; font-size: 25px}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "body {\n",
    "  background: linear-gradient(to right, #20B2AA, #87CEFA);\n",
    "}\n",
    "\n",
    ".lbl_bg {\n",
    "  background-color: #8A8A8A;\n",
    "  color: white;\n",
    "  border-radius: 10px;\n",
    "  padding: 20px;\n",
    "  box-shadow: 4px 4px 4px #708090;\n",
    "}\n",
    "\n",
    ".box_style {\n",
    "  width: 50%;\n",
    "  border: 4px solid #FF00FF;\n",
    "  height: auto;\n",
    "  background: linear-gradient(to right, #90EE90, #32CD32);\n",
    "  border-radius: 10px;\n",
    "  box-shadow: 4px 4px 4px #708090;\n",
    "  padding: 20px;\n",
    "}\n",
    "\n",
    ".box_style1 {\n",
    "  width: 90%;\n",
    "  \n",
    "  font-size: 50px;\n",
    "  background: linear-gradient(to right, #000000, #000000);\n",
    "  border-radius: 10px;\n",
    "  box-shadow: 4px 4px 4px #708090;\n",
    "  border: 5px solid #708090;\n",
    "  color: #FFFFFF;\n",
    "  margin: auto;                             \n",
    "  padding: 10px;\n",
    "  border-radius: 10px;\n",
    "  cursor: pointer;\n",
    "  text-align: center;\n",
    "  display: flex;\n",
    "  align-items: center;\n",
    "}\n",
    ".box_style3 {\n",
    "  width: 90%;\n",
    "  \n",
    "  font-size: 50px;\n",
    "  background: linear-gradient(to right, #000000, #000000);\n",
    "  border-radius: 10px;\n",
    "  box-shadow: 4px 4px 4px #708090;\n",
    "  border: 5px solid #708090;\n",
    "  color: #FFFFFF;\n",
    "  margin: auto;                             \n",
    "  padding: 10px;\n",
    "  border-radius: 10px;\n",
    "  cursor: pointer;\n",
    "}\n",
    "\n",
    ".radio_style1 {\n",
    "  width: 50%;\n",
    "  border: 4px solid #FF00FF;\n",
    "  height: auto;\n",
    "  background: linear-gradient(to right, #7FFFD4, #00FFFF);\n",
    "  border-radius: 10px;\n",
    "  box-shadow: 4px 4px 4px #708090;\n",
    "  padding: 20px;\n",
    "}\n",
    "\n",
    ".box_style2 {\n",
    "  width: 90%;\n",
    "  border: 2px solid #708090;\n",
    "  height: auto;\n",
    "  background: linear-gradient(to right, #8A8A8A, #8A8A8A);\n",
    "  border-radius: 10px;\n",
    "  box-shadow: 4px 4px 4px #708090;\n",
    "  padding: 20px;\n",
    "  color: ##9F9FFF\n",
    "            \n",
    "}\n",
    "\n",
    ".top_spacing {\n",
    "  margin-top: 30px;\n",
    "}\n",
    "\n",
    ".left_spacing {\n",
    "  margin-left: 0px;\n",
    "}\n",
    "\n",
    ".left_spacing_2 {\n",
    "  margin-left: 300px;\n",
    "}\n",
    "\n",
    ".button_style {\n",
    "  border: 5px solid #708090;\n",
    "  background: linear-gradient(to right, #171717, #171717);\n",
    "  color: #1E90FF;\n",
    "  height: auto;                             \n",
    "  padding: 10px;\n",
    "  border-radius: 10px;\n",
    "  font-size: 15px;\n",
    "  box-shadow: 4px 4px 4px #708090;\n",
    "  cursor: pointer;\n",
    "  margin: auto\n",
    "}\n",
    "\n",
    ".top_spacing_2 {\n",
    "  margin-top: -30px;\n",
    "}\n",
    ".white_label { color:white; font-size: 25px}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa68716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\na27078\\Anaconda3\\envs\\env_138\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\na27078\\Anaconda3\\envs\\env_138\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\na27078\\Anaconda3\\envs\\env_138\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\na27078\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "OpenAI tiktoken module is not available for Python < 3.8,Linux ARM64 and AARCH64. Falling back to GPT2TokenizerFast.\n",
      "WARNING:haystack.nodes.answer_generator.openai:OpenAI tiktoken module is not available for Python < 3.8,Linux ARM64 and AARCH64. Falling back to GPT2TokenizerFast.\n",
      "C:\\Users\\na27078\\Anaconda3\\envs\\env_138\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\na27078\\AppData\\Roaming\\Python\\Python38\\site-packages\\espnet2\\gan_tts\\vits\\vits.py:43: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(torch.__version__) >= LooseVersion(\"1.6.0\"):\n",
      "C:\\Users\\na27078\\Anaconda3\\envs\\env_138\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "from haystack.utils import print_documents\n",
    "from haystack.pipelines import DocumentSearchPipeline\n",
    "from haystack.nodes import Seq2SeqGenerator\n",
    "from haystack.pipelines import GenerativeQAPipeline\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import TfidfRetriever\n",
    "from haystack.nodes import TransformersReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.nodes import FARMReader\n",
    "from haystack.nodes import DensePassageRetriever\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import HTML\n",
    "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from scipy.spatial import distance\n",
    "import openai\n",
    "import configparser\n",
    "from string import ascii_lowercase as alc\n",
    "import pprint\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "import traceback\n",
    "from haystack.utils import print_documents\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from haystack import Pipeline, Document\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\", ResourceWarning)\n",
    "warnings.simplefilter(action='ignore', category=ResourceWarning)\n",
    "\n",
    "# from  transformers  import  AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "# import torch\n",
    "# from transformers import AutoConfig, AutoModelForQuestionAnswering\n",
    "readerMem = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)\n",
    "generator = Seq2SeqGenerator(model_name_or_path=\"vblagoje/bart_lfqa\") \n",
    "\n",
    "\n",
    "Patient_query = [\n",
    "        '-Select-',\n",
    "        'How many in-person visits would be required?',\n",
    "        'What will be the duration of study?',\n",
    "        'What are the side effects of the treatment?',\n",
    "        'Will the patient be able to continue their current medications and treatments during the study?',\n",
    "        'I have diabetes can I participate in the trial?',\n",
    "        'What happens if the patient experiences adverse events during the study?',\n",
    "        'I am 81 year old Male, can I participate in the trial?'\n",
    "        \n",
    "    ]\n",
    "\n",
    "Site_query = [\n",
    "    '-Select-',\n",
    "    'What study assessments are followed in the trial?',\n",
    "    'What are the storage conditions for Apibaxin?',\n",
    "    'What measures are in place to protect participant confidentiality and privacy?',\n",
    "    'What is the process of reporting adverse events?',\n",
    "    'In what cases will the trial be terminated?'\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "class Paragraph_Retrieval:\n",
    "    def __init__(self, document_data, user_input):\n",
    "        self.document_data = document_data\n",
    "        self.load_model()\n",
    "        self.query_embedding = self.get_embedding(user_input.strip())\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.model.max_seq_length = 512\n",
    "\n",
    "    def process_document_data(self):\n",
    "\n",
    "        data_dict = dict(zip(self.document_data.Section_Name, self.document_data.Content))\n",
    "        return data_dict\n",
    "\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        embedding = self.model.encode(text, show_progress_bar=False)\n",
    "        return embedding\n",
    "\n",
    "    def similartiy_of_each_para(self, processed_para):\n",
    "\n",
    "#         similarity_score_of_each_para = []\n",
    "#         for i in processed_para:\n",
    "#             if i != '':\n",
    "#                 emb = self.get_embedding(i.strip())\n",
    "\n",
    "#                 cosine_sim = 1 - distance.cosine(self.query_embedding, emb)\n",
    "#                 similarity_score_of_each_para.append((i, cosine_sim))\n",
    "#         return similarity_score_of_each_para\n",
    "        if len(processed_para)!=0:\n",
    "            emb = self.get_embedding(processed_para.strip())\n",
    "            cosine_sim = 1 - distance.cosine(self.query_embedding, emb)\n",
    "            return cosine_sim\n",
    "#             print('First - ', cosine_sim)\n",
    "            \n",
    "        else:\n",
    "            cosine_sim = 0        \n",
    "            return cosine_sim\n",
    "\n",
    "    def run_paragraph_retrieval(self):\n",
    "  \n",
    "        self.document_data['Cosine_score'] = [0]*len(self.document_data)\n",
    "        self.document_data['Cosine_score'] = self.document_data['Content'].apply(lambda x:self.similartiy_of_each_para(x))\n",
    "        final_df = self.document_data.sort_values(by=['Cosine_score'], ascending=False)\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "        return final_df\n",
    "\n",
    "    \n",
    "\n",
    "class PrepareData:\n",
    "    def __init__(self):\n",
    "#         self.protocol_obj = ProtocolDataIngestion()\n",
    "        pass\n",
    "    \n",
    "    def protocolIngestion(self, protocol_number):\n",
    "        if protocol_number=='001':\n",
    "            preprocessed_df = pd.read_csv('Protocol001.csv')\n",
    "            preprocessed_df = preprocessed_df.fillna('')\n",
    "        else:\n",
    "            preprocessed_df = pd.read_csv('Protocol000.csv')\n",
    "            preprocessed_df = preprocessed_df.fillna('')\n",
    "        return preprocessed_df\n",
    "    \n",
    "    def utilsPrepareData(self, protocol_number, preprocessed_df):\n",
    "        \n",
    "        if protocol_number=='001':\n",
    "            to_remove_sections = ['APPENDIX 1 INTERNATIONAL STAGING SYSTEM',\n",
    "                          'APPENDIX 3 PREPARATION AND ADMINISTRATION OF ELOTUZUMAB',\n",
    "                          'Figure 3.1-1: Study Design Schematic',                   \n",
    "                         'LIST OF ABBREVIATIONS',\n",
    "                          'TABLE OF CONTENTS',\n",
    "                         'Table 4-1: Study Drugs for CA204116 Treatment Period',\n",
    "                         'Table 4.5.1-1: Treatment Schedule',\n",
    "                         'Table 4.5.1.2-1: Corticosteroid Premedication',\n",
    "                         'Table 4.5.4.2-1: Dexamethasone Dose Reductions',\n",
    "                         'Table 4.5.4.2-2: Dexamethasone Dose Levels',\n",
    "                         'Table 4.5.4.3-1: Treating Thrombocytopenia Related to Lenalidomide',\n",
    "                         'Table 4.5.4.3-2: Treating Neutropenia Related to Lenalidomide',\n",
    "                         'Table 4.5.4.3-3: Lenalidomide Dose Adjustments in Subjects with Renal Impairment',\n",
    "                         'Table 5.1-1: Screening Procedural Outline (CA204116)',\n",
    "                         'Table 5.1-2: Short-term Procedural Outline (CA204116) Cycles 1 &',\n",
    "                         'Table 5.1-3: Long-term Procedural Outline (CA204116) Cycles 3 and Beyond',\n",
    "                         'Table 5.4.4-1: Safety Laboratory Assessments (may be drawn up to three days prior visit)',\n",
    "                         'Table 5.5.2-1: Bone marrow samples',\n",
    "                         'Table 5.5.4-1: IMWG Criteria for Response',\n",
    "                         'Table 5.5.4-2: IMWG Criteria for Progression',\n",
    "                         'Table 5.6-1: PK and ADA Sampling Schedule',\n",
    "                         ]\n",
    "        else:\n",
    "            to_remove_sections = [\n",
    "                'TABLE OF CONTENTS',\n",
    "                 'Table 4-1: BMS Supplied Study Drugs for CV185316',\n",
    "                 'Table 5.1-1: Baseline and Randomization (CV185316)',\n",
    "                 'Table 5.1-2: Short-term Procedural Outline (CV185316)',\n",
    "                 'Table 8.1-1: Sample Size Adjustment for Non-inferiority and Superiority Test on the Primary Secondary Endpoints'\n",
    "                 'Figure 3.1-1: Study Design Schematic'\n",
    "                  'LIST OF ABBREVIATIONS',\n",
    "                  'Figure 3.1-1: Study Design Schematic']\n",
    "\n",
    "        required_sections = list(set(list(preprocessed_df.Section_Name)) - set(to_remove_sections))\n",
    "        main_df = pd.DataFrame()\n",
    "        for section in required_sections:\n",
    "            main_df = main_df.append(preprocessed_df[preprocessed_df['Section_Name']==section])\n",
    "        main_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return main_df\n",
    "    \n",
    "    \n",
    "    def prepareData(self, protocol_number, preprocessed_df):\n",
    "    \n",
    "        if protocol_number=='001':\n",
    "            to_remove_sections = ['APPENDIX 1 INTERNATIONAL STAGING SYSTEM',\n",
    "                          'APPENDIX 3 PREPARATION AND ADMINISTRATION OF ELOTUZUMAB',\n",
    "                          'Figure 3.1-1: Study Design Schematic',                   \n",
    "                         'LIST OF ABBREVIATIONS',\n",
    "                          'TABLE OF CONTENTS',\n",
    "                         'Table 4-1: Study Drugs for CA204116 Treatment Period',\n",
    "                         'Table 4.5.1-1: Treatment Schedule',\n",
    "                         'Table 4.5.1.2-1: Corticosteroid Premedication',\n",
    "                         'Table 4.5.4.2-1: Dexamethasone Dose Reductions',\n",
    "                         'Table 4.5.4.2-2: Dexamethasone Dose Levels',\n",
    "                         'Table 4.5.4.3-1: Treating Thrombocytopenia Related to Lenalidomide',\n",
    "                         'Table 4.5.4.3-2: Treating Neutropenia Related to Lenalidomide',\n",
    "                         'Table 4.5.4.3-3: Lenalidomide Dose Adjustments in Subjects with Renal Impairment',\n",
    "                         'Table 5.1-1: Screening Procedural Outline (CA204116)',\n",
    "                         'Table 5.1-2: Short-term Procedural Outline (CA204116) Cycles 1 &',\n",
    "                         'Table 5.1-3: Long-term Procedural Outline (CA204116) Cycles 3 and Beyond',\n",
    "                         'Table 5.4.4-1: Safety Laboratory Assessments (may be drawn up to three days prior visit)',\n",
    "                         'Table 5.5.2-1: Bone marrow samples',\n",
    "                         'Table 5.5.4-1: IMWG Criteria for Response',\n",
    "                         'Table 5.5.4-2: IMWG Criteria for Progression',\n",
    "                         'Table 5.6-1: PK and ADA Sampling Schedule',\n",
    "                         ]\n",
    "        else:\n",
    "            to_remove_sections = [\n",
    "                'TABLE OF CONTENTS',\n",
    "                 'Table 4-1: BMS Supplied Study Drugs for CV185316',\n",
    "                 'Table 5.1-1: Baseline and Randomization (CV185316)',\n",
    "                 'Table 5.1-2: Short-term Procedural Outline (CV185316)',\n",
    "                 'Table 8.1-1: Sample Size Adjustment for Non-inferiority and Superiority Test on the Primary Secondary Endpoints'\n",
    "                 'Figure 3.1-1: Study Design Schematic'\n",
    "                  'LIST OF ABBREVIATIONS',\n",
    "                  'Figure 3.1-1: Study Design Schematic']\n",
    "\n",
    "        required_sections = list(set(list(preprocessed_df.Section_Name)) - set(to_remove_sections))\n",
    "        main_df = pd.DataFrame()\n",
    "        for section in required_sections:\n",
    "            main_df = main_df.append(preprocessed_df[preprocessed_df['Section_Name']==section])\n",
    "        main_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        #for haystack\n",
    "        count = 0\n",
    "        all_doc_dict = [] \n",
    "        for index, rows in main_df.iterrows():         \n",
    "            temp_dict = {} \n",
    "            meta_dict = {}\n",
    "            temp_dict['content'] = rows['Content']\n",
    "            meta_dict['name'] = 'Document_'+str(count)\n",
    "            meta_dict['Therapy_Area'] = 'Oncology'\n",
    "    #         count = count+1\n",
    "            temp_dict['meta'] = meta_dict\n",
    "            temp_dict['name'] = rows['Section_Name']+'_'+'Document_'+str(count)\n",
    "            count = count+1\n",
    "\n",
    "            all_doc_dict.append(temp_dict)\n",
    "\n",
    "        return all_doc_dict\n",
    "    \n",
    "    def preprocessData(self, protocol_number, preprocessed_df):\n",
    "        if protocol_number=='001':\n",
    "            to_remove_sections = ['APPENDIX 1 INTERNATIONAL STAGING SYSTEM',\n",
    "                          'APPENDIX 3 PREPARATION AND ADMINISTRATION OF ELOTUZUMAB',\n",
    "                          'Figure 3.1-1: Study Design Schematic',                   \n",
    "                         'LIST OF ABBREVIATIONS',\n",
    "                          'TABLE OF CONTENTS',\n",
    "                         'Table 4-1: Study Drugs for CA204116 Treatment Period',\n",
    "                         'Table 4.5.1-1: Treatment Schedule',\n",
    "                         'Table 4.5.1.2-1: Corticosteroid Premedication',\n",
    "                         'Table 4.5.4.2-1: Dexamethasone Dose Reductions',\n",
    "                         'Table 4.5.4.2-2: Dexamethasone Dose Levels',\n",
    "                         'Table 4.5.4.3-1: Treating Thrombocytopenia Related to Lenalidomide',\n",
    "                         'Table 4.5.4.3-2: Treating Neutropenia Related to Lenalidomide',\n",
    "                         'Table 4.5.4.3-3: Lenalidomide Dose Adjustments in Subjects with Renal Impairment',\n",
    "                         'Table 5.1-1: Screening Procedural Outline (CA204116)',\n",
    "                         'Table 5.1-2: Short-term Procedural Outline (CA204116) Cycles 1 &',\n",
    "                         'Table 5.1-3: Long-term Procedural Outline (CA204116) Cycles 3 and Beyond',\n",
    "                         'Table 5.4.4-1: Safety Laboratory Assessments (may be drawn up to three days prior visit)',\n",
    "                         'Table 5.5.2-1: Bone marrow samples',\n",
    "                         'Table 5.5.4-1: IMWG Criteria for Response',\n",
    "                         'Table 5.5.4-2: IMWG Criteria for Progression',\n",
    "                         'Table 5.6-1: PK and ADA Sampling Schedule',\n",
    "                         ]\n",
    "        else:\n",
    "            to_remove_sections = [\n",
    "                'TABLE OF CONTENTS',\n",
    "                 'Table 4-1: BMS Supplied Study Drugs for CV185316',\n",
    "                 'Table 5.1-1: Baseline and Randomization (CV185316)',\n",
    "                 'Table 5.1-2: Short-term Procedural Outline (CV185316)',\n",
    "                 'Table 8.1-1: Sample Size Adjustment for Non-inferiority and Superiority Test on the Primary Secondary Endpoints'\n",
    "                 'Figure 3.1-1: Study Design Schematic'\n",
    "                  'LIST OF ABBREVIATIONS',\n",
    "                  'Figure 3.1-1: Study Design Schematic']\n",
    "\n",
    "        required_sections = list(set(list(preprocessed_df.Section_Name)) - set(to_remove_sections))\n",
    "        main_df = pd.DataFrame()\n",
    "        for section in required_sections:\n",
    "            main_df = main_df.append(preprocessed_df[preprocessed_df['Section_Name']==section])\n",
    "        main_df.reset_index(drop=True, inplace=True)\n",
    "#         main_df = main_df.groupby('Section_Name')['Content'].agg(' '.join).reset_index()\n",
    "#         main_df['Content'] = main_df['Content'].apply(lambda x : [x])\n",
    "        return main_df\n",
    "    \n",
    "    \n",
    "\n",
    "class Reasoning:\n",
    "    def __init__(self, assertion, data, num_paras):\n",
    "\n",
    "        self.assertion = assertion\n",
    "        self.data = data\n",
    "       \n",
    "        self.num_paras = num_paras\n",
    "        self.final_output = {}\n",
    "    \n",
    "    def ready_paras(self):\n",
    "\n",
    "        self.para_list = []\n",
    "        context = \"Protocol: \\n\"\n",
    "        \n",
    "        for i in range(self.num_paras):\n",
    "            try:\n",
    "                if len(context)/4 < 3000:\n",
    "                    if len(self.data['Content'][i])!=0 or self.data['Content'][i]!= ' ':\n",
    "                        context += '\\npara-' + str(i) + ': ' + self.data['Content'][i]\n",
    "                        self.para_list.append([self.data['Section_Name'][i], self.data['Content'][i], self.data['Cosine_score'][i]])\n",
    "            except:\n",
    "                continue\n",
    "        self.ranked_paras = self.para_list\n",
    "        self.retrieved_paragraphs = context\n",
    "    \n",
    "    def reason_w_GPT3(self):\n",
    "\n",
    "        self.ready_paras()\n",
    "        curr_assertion = 'Refer to the Protocol and provide an answer to the above question not exceeding 2 lines'\n",
    "\n",
    "        gpt3_prompt = self.retrieved_paragraphs + '\\n' + 'Question: ' + self.assertion + '\\n' + curr_assertion\n",
    "#         print('total input tokens', len(gpt3_prompt)/4)\n",
    "        \n",
    "        openai.api_key = '-YOUR-API-KEY-'\n",
    "\n",
    "        response1 = openai.Completion.create(\n",
    "          model=\"text-davinci-003\",\n",
    "          prompt=gpt3_prompt,\n",
    "          temperature=0,\n",
    "          max_tokens=900,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "#         print(response1['choices'][0]['text'])\n",
    "        self.gpt3_reasoning = response1['choices'][0]['text']\n",
    "#         print('output tokens', len(self.gpt3_reasoning)/4)\n",
    "        self.final_output['assertion'] = self.assertion\n",
    "        self.final_output['retrieved_paras'] = self.ranked_paras\n",
    "        self.final_output['reasoning'] = self.gpt3_reasoning\n",
    "        return self.final_output\n",
    "\n",
    "\n",
    "class process:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prepare_data_obj = PrepareData()\n",
    "        \n",
    "   \n",
    "    def get_answer_extractiveQA(self, EQAreader,context, question):\n",
    "        \n",
    "        p = Pipeline()\n",
    "        p.add_node(component=readerMem, name=\"Reader\", inputs=[\"Query\"])\n",
    "        res = p.run(\n",
    "            query=question, documents=[Document(content=context)],params={\"top_k\": 1})\n",
    "        result = {\"query\" : res['query'],\n",
    "                 \"context\" :res['documents'][0].content,\n",
    "                 \"answer\":res['answers'][0].answer\n",
    "                }\n",
    "        return result, res\n",
    "    \n",
    "    def get_answer_generativeQA(self, generator,context, question):\n",
    "        \n",
    "        p = Pipeline()\n",
    "        p.add_node(component=generator, name=\"Generator\", inputs=[\"Query\"])\n",
    "        res = p.run(\n",
    "            query=question, documents=[Document(content=context)],params={\"top_k\": 1})\n",
    "        result = {\"query\" : res['query'],\n",
    "                 \"context\" :res['documents'][0].content,\n",
    "                 \"answer\":res['answers'][0].answer\n",
    "                }\n",
    "        return result, res\n",
    "        \n",
    "    def GPT3Query_1(self, protocol_number, query, retriever_param):\n",
    "        \n",
    "        self.prepare_data_obj = PrepareData()\n",
    "        preprocessed_df = self.prepare_data_obj.protocolIngestion(protocol_number)\n",
    "        main_df = self.prepare_data_obj.preprocessData(protocol_number, preprocessed_df)\n",
    "\n",
    "        passage_retrieve_obj = Paragraph_Retrieval(main_df, query)\n",
    "        final_df = passage_retrieve_obj.run_paragraph_retrieval()\n",
    "\n",
    "        widget_new = widgets.HTML(value='<b> Please give me sometime while I find your answer using GPT.. </b>') \n",
    "        widget_new.add_class('lbl_bg')\n",
    "        display(widget_new)        \n",
    "        r = Reasoning(query, final_df, retriever_param)\n",
    "        final_output = r.reason_w_GPT3()\n",
    "        \n",
    "        answer = final_output['reasoning']\n",
    "        self.to_use_ip_df = pd.DataFrame()\n",
    "        self.to_use_ip_df['Section_Name'] = ['*']*len(final_output['retrieved_paras'])\n",
    "        self.to_use_ip_df['Content'] = ['*']*len(final_output['retrieved_paras'])\n",
    "        \n",
    "        for _ in range(len(final_output['retrieved_paras'])):\n",
    "            self.to_use_ip_df['Section_Name'][_] = final_output['retrieved_paras'][_][0]\n",
    "            self.to_use_ip_df['Content'][_] = final_output['retrieved_paras'][_][1]\n",
    "        \n",
    "        return answer, final_output['retrieved_paras'], self.to_use_ip_df\n",
    "    \n",
    "    def EQAhaystackQuery_1(self, query, retriever_param):\n",
    "    \n",
    "        context = ' '\n",
    "        for i in list(self.to_use_ip_df['Content']):\n",
    "            context = context + ' ' + i\n",
    "            \n",
    "        result, res = self.get_answer_extractiveQA(readerMem,context, query)\n",
    "        widget_new = widgets.HTML(value='<b> Please give me sometime while I find your answer using ExtractiveQA.. </b>') \n",
    "        widget_new.add_class('lbl_bg')\n",
    "        display(widget_new)\n",
    "        \n",
    "        return result, res \n",
    "    \n",
    "    def haystackQuery_1(self, query, retriever_param):\n",
    "\n",
    "        context = ' '\n",
    "        for i in list(self.to_use_ip_df['Content']):\n",
    "            context = context + ' ' + i\n",
    "        result, res = self.get_answer_generativeQA(generator,context, query)    \n",
    "        \n",
    "        widget_new = widgets.HTML(value='<b> Please give me sometime while I find your answer using GenerativeQA.. </b>') \n",
    "        widget_new.add_class('lbl_bg')\n",
    "        display(widget_new)\n",
    "        \n",
    "        return result, res\n",
    "    \n",
    "\n",
    "class UI:\n",
    "    def __init__(self):\n",
    "        self.process_obj = process()\n",
    "    \n",
    "    def display_ui_updated(self):\n",
    "\n",
    "        style= {'description_width': 'initial'}\n",
    "        items_layout = Layout(width='auto') \n",
    "        align_kw = dict(\n",
    "            _css = (('.widget-label', 'min-width', '20ex'),),\n",
    "            margin = '0px 0px 5px 10px'\n",
    "        )\n",
    "        \n",
    "        widget1 = widgets.HTML(value='<b> ENTER QUERY PARAMETERS </b>')\n",
    "        protocol_no = widgets.Dropdown(options=['000', '001'], value = '001', description='<b> Select Protocol Number: </b>',style = style, layout = items_layout)\n",
    "        user_type = widgets.RadioButtons(options=['Patient', 'Site Personnel'], description='<b> Select user type: </b>',style = style, layout = items_layout)\n",
    "\n",
    "        widget2 = widgets.HTML(value='<b> Number of matching content required from Protocol: </b>')\n",
    "\n",
    "        slider = widgets.IntSlider(value=10,\n",
    "                                      min=1,\n",
    "                                      max=10,\n",
    "                                      step=1,\n",
    "                                      description='',\n",
    "                                      disabled=False,\n",
    "                                      continuous_update=False,\n",
    "                                      orientation='horizontal',\n",
    "                                      readout=True,\n",
    "                                      readout_format='d',\n",
    "                                  style = style)\n",
    "\n",
    "\n",
    "        item1 = widgets.HBox([protocol_no], layout = Layout(width = '100%'))\n",
    "        item1 = widgets.VBox([widget1, item1, user_type], layout = Layout(width = '100%'))\n",
    "\n",
    "        item2 = widgets.HBox([widget2], layout = Layout(width = '100%'))\n",
    "        item2 = widgets.VBox([widget2, slider], layout = Layout(width = '100%'))\n",
    "\n",
    "        final_list = ['-Select-']\n",
    "        # Create dropdown widget\n",
    "        item_new = widgets.Dropdown(\n",
    "\n",
    "            options = final_list,\n",
    "            description='<b> Frequently Asked Question (FAQ): </b>', style = style, layout = items_layout, **align_kw, \n",
    "        )\n",
    "\n",
    "        # Function to update final list\n",
    "        def update_final_list(change):\n",
    "            if change['new'] == 'Patient':\n",
    "                item_new.options = Patient_query\n",
    "            else:\n",
    "                item_new.options = Site_query\n",
    "\n",
    "        user_type.observe(update_final_list, names='value')\n",
    "\n",
    "        item_new_ = widgets.Text(placeholder= 'Input query.....', description='<b> Please enter your query </b>', disabled=False, style = style, layout = items_layout, **align_kw)\n",
    "        item_new.add_class('top_spacing')\n",
    "        item_new.add_class('left_spacing')\n",
    "        item_new_.add_class('top_spacing')\n",
    "\n",
    "        item3 = widgets.HBox([item1], layout = Layout(width = '100%'))\n",
    "        item4 = widgets.VBox([item_new_, item_new], layout = Layout(width = '100%'))\n",
    "        item5 = widgets.VBox([item3, item4, item2], layout = Layout(width = '100%'))\n",
    "        b1 = widgets.Button(description='Generate Response', button_style= 'success', layout= widgets.Layout(\n",
    "                    width='35%', positioning = 'center'))#layout=Layout(positioning='right'))\n",
    "\n",
    "        b1.layout.align_items = 'center' \n",
    "        b1.add_class(\"top_spacing\")\n",
    "        b1.add_class(\"button_style\")\n",
    "        h1 = widgets.Box([widgets.HTML(value= \"<b style='color: white;font-family: Georgia; margin-top: 50%'> Prompt-based Answering system</b>\").add_class('white_label')], layout=Layout(justify_content= 'space-around', width='100%', color='white'))\n",
    "        \n",
    "        img = widgets.Box([widgets.HTML(value= \"<b style='font-size: 10px; font-family: Georgia; color: white; margin-left: 0%'>Powered by</b> <img src=https://i.kym-cdn.com/entries/icons/original/000/040/858/cover7.jpg style='width: 170px; height: 75px; margin-left: 0%; '>\")], \n",
    "        layout=Layout(justify_content= 'space-around', width='20%', height='100%',margin_top= '0%'))\n",
    "        heading_box = widgets.HBox([h1, img], layout = Layout(width = '100%'))\n",
    "        heading_box.add_class(\"box_style1\")\n",
    "        \n",
    "        \n",
    "        heading_box.add_class(\"box_style1\")\n",
    "        display(heading_box)\n",
    "        item6 = widgets.VBox([item5, b1], layout = Layout(width = '100%'))\n",
    "        item6.add_class('box_style2')\n",
    "        display(item6)\n",
    "        out = widgets.Output()\n",
    "\n",
    "\n",
    "        @out.capture()\n",
    "        def processUIQuery(b):\n",
    "\n",
    "            with out:\n",
    "                clear_output()\n",
    "                try:\n",
    "                    \n",
    "                    global Protocol_Number\n",
    "                    global User_Type\n",
    "                    global FAQ\n",
    "                    global Query\n",
    "                    global Params\n",
    "                    global flag\n",
    "                    \n",
    "                    Protocol_Number = protocol_no.value\n",
    "                    FAQ = item_new.value\n",
    "                    Query = item_new_.value\n",
    "                    Params = slider.value\n",
    "                    \n",
    "                    if FAQ!='-Select-':\n",
    "                        GPT_starttime = time.time()\n",
    "                        #process\n",
    "                        GPTanswer, GPTmeta, df = self.process_obj.GPT3Query_1(Protocol_Number, FAQ, Params)\n",
    "                        GPT_endtime = time.time()\n",
    "                        GPT_delta = GPT_endtime - GPT_starttime\n",
    "                        print('Time taken by GPT : ' + str(GPT_delta) + ' seconds')\n",
    "                        EQ_starttime = time.time()\n",
    "                        EQAanswer_, EQAdocuments_list = self.process_obj.EQAhaystackQuery_1(FAQ, Params)\n",
    "                        EQendtime = time.time()\n",
    "                        EQ_delta = EQendtime-EQ_starttime\n",
    "                        print('Time taken by ExtractiveQA : ' + str(EQ_delta) + ' seconds')\n",
    "                        GQ_starttime = time.time()\n",
    "                        GQanswer, GQcontent = self.process_obj.haystackQuery_1(FAQ, Params)\n",
    "                        GQ_endtime = time.time()\n",
    "                        GQ_delta = GQ_endtime-GQ_starttime\n",
    "                        print('Time taken by GenerativeQA : ' + str(GQ_delta) + ' seconds')\n",
    "                    \n",
    "                    else:\n",
    "#                         GPTanswer, GPTmeta, df = self.process_obj.GPT3Query_1(Protocol_Number, Query, Params)\n",
    "#                         EQAanswer_, EQAdocuments_list = self.process_obj.EQAhaystackQuery_1(Query, Params)\n",
    "#                         GQanswer, GQcontent = self.process_obj.haystackQuery_1(Query, Params)\n",
    "                        GPT_starttime = time.time()\n",
    "                        #process\n",
    "                        GPTanswer, GPTmeta, df = self.process_obj.GPT3Query_1(Protocol_Number, Query, Params)\n",
    "                        GPT_endtime = time.time()\n",
    "                        GPT_delta = GPT_endtime - GPT_starttime\n",
    "                        print('Time taken by GPT : ' + str(GPT_delta) + ' seconds')\n",
    "                        EQ_starttime = time.time()\n",
    "                        EQAanswer_, EQAdocuments_list = self.process_obj.EQAhaystackQuery_1(Query, Params)\n",
    "                        EQendtime = time.time()\n",
    "                        EQ_delta = EQendtime-EQ_starttime\n",
    "                        print('Time taken by ExtractiveQA : ' + str(EQ_delta) + ' seconds')\n",
    "                        GQ_starttime = time.time()\n",
    "                        GQanswer, GQcontent = self.process_obj.haystackQuery_1(Query, Params)\n",
    "                        GQ_endtime = time.time()\n",
    "                        GQ_delta = GQ_endtime-GQ_starttime\n",
    "                        print('Time taken by GenerativeQA : ' + str(GQ_delta) + ' seconds')\n",
    "                        \n",
    "                    #GenerativeQA display\n",
    "                    df = df.groupby('Section_Name')['Content'].agg('\\n'.join).reset_index()\n",
    "                    \n",
    "                    HSanswer = GQanswer['answer']\n",
    "                    if not HSanswer.endswith('.'):\n",
    "                        split_answer = sent_tokenize(HSanswer)\n",
    "                        HSanswer = ' '.join(split_answer[:-1])\n",
    "\n",
    "                                        \n",
    "                    HSanswer_display = widgets.HTML(value='<b> Answer to your question : </b>')\n",
    "                    HSanswer_widget = widgets.HTML(value=HSanswer)\n",
    "#                     HScontext = GQanswer['context']\n",
    "#                     HScontext_display = widgets.HTML(value='<b> Answer context : </b>')\n",
    "#                     HScontext_widget = widgets.HTML(value=HScontext)\n",
    "                    HSreference_display = widgets.HTML(value='<b> Reference sections from Protocol : </b>')\n",
    "\n",
    "                    item7 = widgets.VBox([HSanswer_display, HSanswer_widget, HSreference_display], layout = Layout(width = '100%'))\n",
    "                    \n",
    "                    HSContext = ' '\n",
    "                    for i in range(len(df)):\n",
    "                        HSContext = HSContext + '<b>Section Name : </b>' + df['Section_Name'][i] + '<br>' + '<b>Section Content : </b>' + df['Content'][i] + '<br>'\n",
    "\n",
    "                    HSContext = HSContext.replace('\\n', '<br>')\n",
    "\n",
    "                    HSContext_display = widgets.HTML(value=HSContext)\n",
    "                    \n",
    "                    item8 = widgets.VBox([item7, HSContext_display], layout = Layout(width = '100%'))\n",
    "\n",
    "                    #GPT3\n",
    "                    \n",
    "#                     if not GPTanswer.endswith('.'):\n",
    "#                         split_answer = sent_tokenize(GPTanswer)\n",
    "#                         GPTanswer = ' '.join(split_answer[:-1])\n",
    "\n",
    "                    GPTanswer_display = widgets.HTML(value = '<b> Answer to your question : </b>')\n",
    "                    GPTanswer_widget = widgets.HTML(value = GPTanswer)\n",
    "\n",
    "                    \n",
    "                    GPTreference_display = widgets.HTML(value='<b> Reference sections from Protocol : </b>')\n",
    "                    item9 = widgets.VBox([GPTanswer_display, GPTanswer_widget, GPTreference_display], layout = Layout(width = '100%'))\n",
    "\n",
    "                    GPTContext = ' '\n",
    "\n",
    "                    for i in range(len(df)):\n",
    "                       \n",
    "                        GPTContext = GPTContext + '<b>Section Name : </b>' + df['Section_Name'][i] + '<br>' + '<b>Section Content : </b>' + df['Content'][i] + '<br>'\n",
    "\n",
    "                    GPTcontext_display = widgets.HTML(value=GPTContext)       \n",
    "                    item10 = widgets.VBox([item9, GPTcontext_display], layout = Layout(width = '100%'))\n",
    "\n",
    "                    #EQA       \n",
    "                    \n",
    "                    EQanswer = EQAanswer_['answer']\n",
    "                    EQAanswer_display = widgets.HTML(value='<b> Answer to your question : </b>')\n",
    "                    EQAanswer_widget = widgets.HTML(value=EQanswer)\n",
    "#                     EQcontext = EQAanswer_['context']\n",
    "#                     EQcontext_display = widgets.HTML(value='<b> Answer context : </b>')\n",
    "#                     EQcontext_widget = widgets.HTML(value=EQcontext)\n",
    "                    EQAreference_display = widgets.HTML(value='<b> Reference sections from Protocol : </b>')\n",
    "\n",
    "                    item11 = widgets.VBox([EQAanswer_display, EQAanswer_widget, EQAreference_display], layout = Layout(width = '100%'))\n",
    "                    \n",
    "                    EQAContext = ' '\n",
    "                    for i in range(len(df)):\n",
    "                        EQAContext = EQAContext + '<b>Section Name : </b>' + df['Section_Name'][i] + '<br>' + '<b>Section Content : </b>' + df['Content'][i] + '<br>'\n",
    "\n",
    "                    EQAContext = EQAContext.replace('\\n', '<br>')\n",
    "\n",
    "                    EQAcontext_display = widgets.HTML(value=EQAContext)\n",
    "                    \n",
    "                    item12 = widgets.VBox([item11, EQAcontext_display], layout = Layout(width = '100%'))\n",
    "\n",
    "                    tab_nest = widgets.Tab()\n",
    "                    tab_nest.children = [item10, item8, item12]\n",
    "                    tab_nest.titles = ('GPT3','GenerativeQA', 'ExtractiveQA')\n",
    "                    tab_nest.set_title(0, 'GPT3')\n",
    "                    tab_nest.set_title(1, 'GenerativeQA')\n",
    "                    tab_nest.set_title(2, 'ExtractiveQA')\n",
    "                    tab_nest.add_class(\"box_style3\")\n",
    "#                     tab_nest.add_class('box_style2')\n",
    "\n",
    "                    display(tab_nest)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)   \n",
    "                    traceback.print_exc()\n",
    "                    widget_nafisa = widgets.HTML(value='<b> Please enter missing parameters! </b>')\n",
    "                    widget_nafisa.add_class('lbl_bg')\n",
    "                    display(widget_nafisa)\n",
    "\n",
    "        b1.on_click(processUIQuery)\n",
    "\n",
    "        display(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3571c25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52cc7af641c4e20bca5921c24d4b38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Box(children=(HTML(value=\"<b style='color: white;font-family: Georgia; margin-top: 50%'> Prompt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8411412f67ca443eac55d31c9864dd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(VBox(children=(HTML(value='<b> ENTER QUERY PARAMETERS </b>'), HBo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ceeb8f697d404cbe2d16d4be99a763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ui_obj = UI()\n",
    "ui_obj.display_ui_updated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923e7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
